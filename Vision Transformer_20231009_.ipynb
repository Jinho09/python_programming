{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1a7ed4b0-7105-4446-a7b6-8316dea66ec6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 1000])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "class PatchEmbedding(nn.Module):\n",
    "    def __init__(self, in_channels=3, patch_size=16, emb_size=768):\n",
    "        super().__init__()\n",
    "        self.patch_size = patch_size\n",
    "        self.proj = nn.Conv2d(in_channels, emb_size, kernel_size=patch_size, stride=patch_size)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.proj(x)\n",
    "        (B, C, H, W) = x.shape\n",
    "        x = x.view(B, C, H * W)\n",
    "        x = x.permute(0, 2, 1)\n",
    "        return x\n",
    "\n",
    "class VisionTransformer(nn.Module):\n",
    "    def __init__(self, in_channels=3, patch_size=16, emb_size=768, img_size=224, num_classes=1000, num_layers=12):\n",
    "        super().__init__()\n",
    "\n",
    "        self.patch_embedding = PatchEmbedding(in_channels, patch_size, emb_size)\n",
    "        num_patches = (img_size // patch_size) ** 2\n",
    "\n",
    "        self.cls_token = nn.Parameter(torch.randn(1, 1, emb_size))\n",
    "        self.position_embedding = nn.Parameter(torch.randn(1, num_patches + 1, emb_size))\n",
    "        self.dropout = nn.Dropout(0.1)\n",
    "\n",
    "        # batch_first=True 옵션 추가\n",
    "        encoder_layer = nn.TransformerEncoderLayer(emb_size, 8, batch_first=True)\n",
    "        self.transformer = nn.TransformerEncoder(encoder_layer, num_layers)\n",
    "        \n",
    "        self.mlp_head = nn.Sequential(\n",
    "            nn.Linear(emb_size, emb_size),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(emb_size, num_classes)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.patch_embedding(x)\n",
    "        B, _, _ = x.shape\n",
    "\n",
    "        cls_tokens = self.cls_token.expand(B, -1, -1)\n",
    "        x = torch.cat([cls_tokens, x], dim=1)\n",
    "\n",
    "        x = x + self.position_embedding\n",
    "        x = self.dropout(x)\n",
    "\n",
    "        x = self.transformer(x)\n",
    "\n",
    "        x = x.mean(dim=1)\n",
    "        x = self.mlp_head(x)\n",
    "\n",
    "        return x\n",
    "\n",
    "# Model 생성 및 예시 입력 통과\n",
    "model = VisionTransformer()\n",
    "x = torch.rand(1, 3, 224, 224)\n",
    "print(model(x).shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bf68eaef-9bd0-4a61-b480-a2607bd2bc8d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cpu\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torchvision import datasets, transforms\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "\n",
    "# GPU 사용 가능한지 확인\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "# 데이터 전처리\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.ToTensor(),\n",
    "])\n",
    "\n",
    "# 데이터 로더 설정\n",
    "train_dataset = datasets.ImageFolder(root='C:\\\\Users\\\\Jinho\\\\Downloads\\\\20231007\\\\CYH13\\\\BottomSideWall\\\\train', transform=transform)\n",
    "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
    "\n",
    "# VisionTransformer 모델 정의 (이전 코드에서 정의되었다고 가정)\n",
    "model = VisionTransformer()\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "798a702f-0f6b-4440-ad2c-cc6124fc4860",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0/10 | Batch 0/26 | Current Loss: 6.6568 | Cumulative Accuracy: 0.00%\n",
      "Epoch 0/10 | Batch 10/26 | Current Loss: 0.7721 | Cumulative Accuracy: 50.00%\n",
      "Epoch 0/10 | Batch 20/26 | Current Loss: 0.8478 | Cumulative Accuracy: 52.23%\n",
      "Epoch 0/10 Finished. Average Loss: 1.1739 | Overall Accuracy: 51.05%\n",
      "==================================================\n",
      "Epoch 1/10 | Batch 0/26 | Current Loss: 0.7036 | Cumulative Accuracy: 62.50%\n",
      "Epoch 1/10 | Batch 10/26 | Current Loss: 0.6967 | Cumulative Accuracy: 55.40%\n",
      "Epoch 1/10 | Batch 20/26 | Current Loss: 0.7711 | Cumulative Accuracy: 53.27%\n",
      "Epoch 1/10 Finished. Average Loss: 0.7074 | Overall Accuracy: 54.38%\n",
      "==================================================\n",
      "Epoch 2/10 | Batch 0/26 | Current Loss: 0.6996 | Cumulative Accuracy: 43.75%\n",
      "Epoch 2/10 | Batch 10/26 | Current Loss: 0.7604 | Cumulative Accuracy: 52.84%\n",
      "Epoch 2/10 | Batch 20/26 | Current Loss: 0.6910 | Cumulative Accuracy: 53.57%\n",
      "Epoch 2/10 Finished. Average Loss: 0.7160 | Overall Accuracy: 54.87%\n",
      "==================================================\n",
      "Epoch 3/10 | Batch 0/26 | Current Loss: 0.6837 | Cumulative Accuracy: 59.38%\n",
      "Epoch 3/10 | Batch 10/26 | Current Loss: 0.7745 | Cumulative Accuracy: 52.84%\n",
      "Epoch 3/10 | Batch 20/26 | Current Loss: 0.6032 | Cumulative Accuracy: 58.33%\n",
      "Epoch 3/10 Finished. Average Loss: 0.6863 | Overall Accuracy: 59.06%\n",
      "==================================================\n",
      "Epoch 4/10 | Batch 0/26 | Current Loss: 0.6800 | Cumulative Accuracy: 59.38%\n",
      "Epoch 4/10 | Batch 10/26 | Current Loss: 0.6493 | Cumulative Accuracy: 56.53%\n",
      "Epoch 4/10 | Batch 20/26 | Current Loss: 0.6391 | Cumulative Accuracy: 58.93%\n",
      "Epoch 4/10 Finished. Average Loss: 0.6833 | Overall Accuracy: 59.56%\n",
      "==================================================\n",
      "Epoch 5/10 | Batch 0/26 | Current Loss: 0.6927 | Cumulative Accuracy: 68.75%\n",
      "Epoch 5/10 | Batch 10/26 | Current Loss: 0.6216 | Cumulative Accuracy: 59.09%\n",
      "Epoch 5/10 | Batch 20/26 | Current Loss: 0.6887 | Cumulative Accuracy: 54.91%\n",
      "Epoch 5/10 Finished. Average Loss: 0.7082 | Overall Accuracy: 54.01%\n",
      "==================================================\n",
      "Epoch 6/10 | Batch 0/26 | Current Loss: 0.8304 | Cumulative Accuracy: 53.12%\n",
      "Epoch 6/10 | Batch 10/26 | Current Loss: 0.6841 | Cumulative Accuracy: 57.67%\n",
      "Epoch 6/10 | Batch 20/26 | Current Loss: 0.6689 | Cumulative Accuracy: 56.25%\n",
      "Epoch 6/10 Finished. Average Loss: 0.7018 | Overall Accuracy: 56.47%\n",
      "==================================================\n",
      "Epoch 7/10 | Batch 0/26 | Current Loss: 0.6955 | Cumulative Accuracy: 40.62%\n",
      "Epoch 7/10 | Batch 10/26 | Current Loss: 0.6822 | Cumulative Accuracy: 54.26%\n",
      "Epoch 7/10 | Batch 20/26 | Current Loss: 0.6435 | Cumulative Accuracy: 56.25%\n",
      "Epoch 7/10 Finished. Average Loss: 0.6858 | Overall Accuracy: 56.10%\n",
      "==================================================\n",
      "Epoch 8/10 | Batch 0/26 | Current Loss: 0.7024 | Cumulative Accuracy: 46.88%\n",
      "Epoch 8/10 | Batch 10/26 | Current Loss: 0.6314 | Cumulative Accuracy: 53.69%\n",
      "Epoch 8/10 | Batch 20/26 | Current Loss: 0.7686 | Cumulative Accuracy: 56.40%\n",
      "Epoch 8/10 Finished. Average Loss: 0.6862 | Overall Accuracy: 57.58%\n",
      "==================================================\n",
      "Epoch 9/10 | Batch 0/26 | Current Loss: 0.6678 | Cumulative Accuracy: 62.50%\n",
      "Epoch 9/10 | Batch 10/26 | Current Loss: 0.6562 | Cumulative Accuracy: 61.65%\n",
      "Epoch 9/10 | Batch 20/26 | Current Loss: 0.6503 | Cumulative Accuracy: 55.65%\n",
      "Epoch 9/10 Finished. Average Loss: 0.6875 | Overall Accuracy: 56.60%\n",
      "==================================================\n",
      "Training finished.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# 학습 루프\n",
    "num_epochs = 10\n",
    "print_every = 10  # 10번의 미니배치마다 출력\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    correct = 0\n",
    "    for batch_idx, (data, target) in enumerate(train_loader):\n",
    "        data, target = data.to(device), target.to(device)  # 데이터를 GPU로 이동\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        output = model(data)\n",
    "        loss = criterion(output, target)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # 손실률과 정확도 계산\n",
    "        total_loss += loss.item() * data.size(0)\n",
    "        _, predicted = output.max(1)\n",
    "        correct += predicted.eq(target).sum().item()\n",
    "\n",
    "        # 실시간 정보 출력\n",
    "        if batch_idx % print_every == 0:\n",
    "            current_loss = loss.item()\n",
    "            current_accuracy = 100. * correct / ((batch_idx + 1) * train_loader.batch_size)\n",
    "            print(f\"Epoch {epoch}/{num_epochs} | Batch {batch_idx}/{len(train_loader)} | Current Loss: {current_loss:.4f} | Cumulative Accuracy: {current_accuracy:.2f}%\")\n",
    "\n",
    "    # 에포크별 평균 손실과 정확도\n",
    "    avg_loss = total_loss / len(train_loader.dataset)\n",
    "    accuracy = 100. * correct / len(train_loader.dataset)\n",
    "\n",
    "    print(f\"Epoch {epoch}/{num_epochs} Finished. Average Loss: {avg_loss:.4f} | Overall Accuracy: {accuracy:.2f}%\")\n",
    "    print(\"=\"*50)\n",
    "\n",
    "print(\"Training finished.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a1980b9-0470-4a96-a1e5-9199c7b86137",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
